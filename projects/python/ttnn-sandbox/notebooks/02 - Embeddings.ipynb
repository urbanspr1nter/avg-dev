{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6edc4af",
   "metadata": {},
   "source": [
    "# Embeddings Example with TTNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040de51e",
   "metadata": {},
   "source": [
    "First define some variables that we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62cdd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 \n",
    "vocab_size = 50257\n",
    "output_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b76ee7",
   "metadata": {},
   "source": [
    "Import `torch` and `ttnn` libraries. If `ttnn` is succesffully imported, you'll see some logging related to `Config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0835e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:07:12.596 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012ada2",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "We will use the short story `the-verdict.txt` as our sample dataset. Download the text to `data/the-verdict.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"data/the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    \n",
    "    file_path = \"data/the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e50ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap g\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(raw_text[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27deb3b1",
   "metadata": {},
   "source": [
    "Define the `context_length` and `batch_size` to be used throughout the notebook. The `batch_size` is the number of tensors that we get total for each iteration of our dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e347964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 4\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde998c2",
   "metadata": {},
   "source": [
    "`pip` install `tiktoken` if not already in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1242b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/avgdev/code/avg-dev/projects/python/ttnn-sandbox/.venv/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/avgdev/code/avg-dev/projects/python/ttnn-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/avgdev/code/avg-dev/projects/python/ttnn-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/avgdev/code/avg-dev/projects/python/ttnn-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/avgdev/code/avg-dev/projects/python/ttnn-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Using cached tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tiktoken]\n",
      "\u001b[1A\u001b[2KSuccessfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6fd6d",
   "metadata": {},
   "source": [
    "## Creating Custom Dataloader\n",
    "\n",
    "This dataloader will store our inputs and targets tensors. They are still in `torch` form. We can initialize the dataloader using the `create_dataloader` function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f177419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self._input_ids = []\n",
    "        self._target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "\n",
    "            self._input_ids.append(torch.tensor(input_chunk))\n",
    "            self._target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._input_ids[idx], self._target_ids[idx]\n",
    "    \n",
    "def create_dataloader(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef5bb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,   367,  2885,  1464],\n",
       "         [ 1807,  3619,   402,   271],\n",
       "         [10899,  2138,   257,  7026],\n",
       "         [15632,   438,  2016,   257],\n",
       "         [  922,  5891,  1576,   438],\n",
       "         [  568,   340,   373,   645],\n",
       "         [ 1049,  5975,   284,   502],\n",
       "         [  284,  3285,   326,    11]]),\n",
       " tensor([[  367,  2885,  1464,  1807],\n",
       "         [ 3619,   402,   271, 10899],\n",
       "         [ 2138,   257,  7026, 15632],\n",
       "         [  438,  2016,   257,   922],\n",
       "         [ 5891,  1576,   438,   568],\n",
       "         [  340,   373,   645,  1049],\n",
       "         [ 5975,   284,   502,   284],\n",
       "         [ 3285,   326,    11,   287]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader(\n",
    "    raw_text, \n",
    "    batch_size=batch_size, \n",
    "    max_length=context_length, \n",
    "    stride=context_length,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01263975",
   "metadata": {},
   "source": [
    "# Torch Embeddings Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3436c9",
   "metadata": {},
   "source": [
    "It is easier to do this exercise first using `torch` and then we'll adapt and rewrite it using `ttnn` to the best of our ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9156b825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8662, -0.0436,  1.5156,  ...,  0.2127, -3.2786, -0.5743],\n",
       "          [ 1.3781, -0.1197,  0.0313,  ...,  0.2775,  0.3691,  0.2817],\n",
       "          [-0.4382, -2.2696, -0.1110,  ..., -0.2127, -1.9321, -0.6311],\n",
       "          [ 1.1630,  0.4681, -1.2171,  ...,  0.8214,  0.1959,  0.8996]],\n",
       " \n",
       "         [[-0.4888,  0.3827, -1.6942,  ...,  1.2904,  0.5649,  0.6273],\n",
       "          [ 0.1420, -0.7241, -1.1617,  ..., -1.3439,  1.6568, -0.6777],\n",
       "          [-0.8134,  0.1044,  0.1628,  ...,  0.7499, -0.0285, -0.6549],\n",
       "          [-0.1758,  0.5710,  0.9514,  ...,  4.1751,  1.1144, -2.0448]],\n",
       " \n",
       "         [[-0.8470,  0.5591, -0.4546,  ..., -0.1664, -0.5267, -0.0662],\n",
       "          [ 0.2358, -0.0514,  0.6138,  ...,  0.5978,  0.0912,  0.6538],\n",
       "          [-1.0551, -0.2106,  1.7852,  ..., -2.0223,  1.3278, -1.5084],\n",
       "          [-1.0741,  1.2759,  0.2565,  ...,  1.2733, -1.2093,  0.8373]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.4378,  1.2705,  0.2923,  ..., -0.5806, -0.2155,  0.4700],\n",
       "          [ 2.2364, -1.3076, -0.6452,  ...,  0.2542, -0.2225,  1.9249],\n",
       "          [-1.3900,  2.6454,  0.6677,  ..., -1.5780, -0.1178,  0.2074],\n",
       "          [-1.2422,  0.9460, -0.5451,  ..., -0.3540, -0.0984,  0.3015]],\n",
       " \n",
       "         [[ 0.0410,  0.7293, -1.7027,  ..., -0.7156,  1.1727, -1.3483],\n",
       "          [-1.0439, -2.0379,  0.5442,  ..., -1.3055,  0.2887,  1.0655],\n",
       "          [ 0.2804,  0.4923, -0.0431,  ...,  0.4254, -0.2360, -0.9054],\n",
       "          [-1.8156,  0.1849, -2.5673,  ..., -0.2476,  1.5403, -0.5366]],\n",
       " \n",
       "         [[ 0.2804,  0.4923, -0.0431,  ...,  0.4254, -0.2360, -0.9054],\n",
       "          [ 0.2908,  1.0421, -0.3769,  ...,  0.9383,  1.2396,  0.7988],\n",
       "          [ 1.4633, -0.1879,  1.9060,  ...,  1.6800, -0.4444, -0.4032],\n",
       "          [-0.6902, -0.9788, -0.2736,  ..., -0.5010, -1.2021, -0.5652]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([8, 4, 256]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "token_embeddings, token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9003669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6888, -0.6568, -0.8298,  ..., -0.3943,  1.1660, -0.2200],\n",
       "         [ 2.4855,  1.4199, -0.4613,  ..., -0.4492, -0.6024,  0.7097],\n",
       "         [ 1.2576, -1.4132,  0.4963,  ..., -3.4569,  1.3010,  0.8833],\n",
       "         [-1.2176, -0.0290,  0.2775,  ...,  0.5771,  1.4045,  0.8579]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([4, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "positional_embeddings = positional_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "positional_embeddings, positional_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da79262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.7740e-01, -7.0034e-01,  6.8585e-01,  ..., -1.8157e-01,\n",
       "           -2.1127e+00, -7.9434e-01],\n",
       "          [ 3.8636e+00,  1.3002e+00, -4.3003e-01,  ..., -1.7162e-01,\n",
       "           -2.3325e-01,  9.9138e-01],\n",
       "          [ 8.1939e-01, -3.6828e+00,  3.8526e-01,  ..., -3.6697e+00,\n",
       "           -6.3107e-01,  2.5222e-01],\n",
       "          [-5.4543e-02,  4.3906e-01, -9.3961e-01,  ...,  1.3985e+00,\n",
       "            1.6004e+00,  1.7574e+00]],\n",
       " \n",
       "         [[ 1.9999e-01, -2.7411e-01, -2.5240e+00,  ...,  8.9612e-01,\n",
       "            1.7308e+00,  4.0726e-01],\n",
       "          [ 2.6275e+00,  6.9581e-01, -1.6231e+00,  ..., -1.7930e+00,\n",
       "            1.0544e+00,  3.1978e-02],\n",
       "          [ 4.4418e-01, -1.3088e+00,  6.5906e-01,  ..., -2.7070e+00,\n",
       "            1.2725e+00,  2.2835e-01],\n",
       "          [-1.3934e+00,  5.4199e-01,  1.2289e+00,  ...,  4.7522e+00,\n",
       "            2.5189e+00, -1.1869e+00]],\n",
       " \n",
       "         [[-1.5829e-01, -9.7678e-02, -1.2844e+00,  ..., -5.6076e-01,\n",
       "            6.3923e-01, -2.8620e-01],\n",
       "          [ 2.7213e+00,  1.3685e+00,  1.5247e-01,  ...,  1.4866e-01,\n",
       "           -5.1122e-01,  1.3635e+00],\n",
       "          [ 2.0243e-01, -1.6237e+00,  2.2815e+00,  ..., -5.4793e+00,\n",
       "            2.6288e+00, -6.2508e-01],\n",
       "          [-2.2917e+00,  1.2469e+00,  5.3399e-01,  ...,  1.8504e+00,\n",
       "            1.9521e-01,  1.6951e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1265e+00,  6.1367e-01, -5.3744e-01,  ..., -9.7489e-01,\n",
       "            9.5046e-01,  2.4995e-01],\n",
       "          [ 4.7219e+00,  1.1226e-01, -1.1065e+00,  ..., -1.9495e-01,\n",
       "           -8.2489e-01,  2.6346e+00],\n",
       "          [-1.3239e-01,  1.2323e+00,  1.1640e+00,  ..., -5.0349e+00,\n",
       "            1.1832e+00,  1.0907e+00],\n",
       "          [-2.4598e+00,  9.1693e-01, -2.6763e-01,  ...,  2.2315e-01,\n",
       "            1.3061e+00,  1.1594e+00]],\n",
       " \n",
       "         [[ 7.2976e-01,  7.2557e-02, -2.5325e+00,  ..., -1.1099e+00,\n",
       "            2.3386e+00, -1.5684e+00],\n",
       "          [ 1.4416e+00, -6.1796e-01,  8.2890e-02,  ..., -1.7547e+00,\n",
       "           -3.1372e-01,  1.7752e+00],\n",
       "          [ 1.5380e+00, -9.2087e-01,  4.5318e-01,  ..., -3.0315e+00,\n",
       "            1.0650e+00, -2.2072e-02],\n",
       "          [-3.0332e+00,  1.5587e-01, -2.2898e+00,  ...,  3.2950e-01,\n",
       "            2.9448e+00,  3.2126e-01]],\n",
       " \n",
       "         [[ 9.6918e-01, -1.6448e-01, -8.7287e-01,  ...,  3.1130e-02,\n",
       "            9.2999e-01, -1.1254e+00],\n",
       "          [ 2.7763e+00,  2.4620e+00, -8.3819e-01,  ...,  4.8919e-01,\n",
       "            6.3719e-01,  1.5085e+00],\n",
       "          [ 2.7209e+00, -1.6010e+00,  2.4023e+00,  ..., -1.7769e+00,\n",
       "            8.5660e-01,  4.8011e-01],\n",
       "          [-1.9077e+00, -1.0078e+00,  3.9049e-03,  ...,  7.6154e-02,\n",
       "            2.0236e-01,  2.9265e-01]]], grad_fn=<AddBackward0>),\n",
       " torch.Size([8, 4, 256]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + positional_embeddings\n",
    "input_embeddings, input_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b560f09",
   "metadata": {},
   "source": [
    "# ttnn Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc0f34",
   "metadata": {},
   "source": [
    "Let's rewrite everything using `ttnn` but first let's open a device by using `open_device` and storing the handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93d87e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-04-28 16:37:58.737\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-04-28 16:37:58.752\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-28 16:37:58.754\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-04-28 16:37:58.755\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-28 16:37:58.756\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-04-28 16:37:58.756\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-04-28 16:37:58.882\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f39897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ttnn.Tensor([[   40,   367,  ...,  2885,  1464],\n",
       "              [ 1807,  3619,  ...,   402,   271],\n",
       "              ...,\n",
       "              [ 1049,  5975,  ...,   284,   502],\n",
       "              [  284,  3285,  ...,   326,    11]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR),\n",
       " ttnn.Tensor([[  367,  2885,  ...,  1464,  1807],\n",
       "              [ 3619,   402,  ...,   271, 10899],\n",
       "              ...,\n",
       "              [ 5975,   284,  ...,   502,   284],\n",
       "              [ 3285,   326,  ...,    11,   287]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ttnn = ttnn.from_torch(inputs, dtype=ttnn.uint32)\n",
    "targets_ttnn = ttnn.from_torch(targets, dtype=ttnn.uint32)\n",
    "\n",
    "inputs_ttnn, targets_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22daac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ttnn.Tensor([[   40,   367,  ...,  2885,  1464],\n",
       "              [ 1807,  3619,  ...,   402,   271],\n",
       "              ...,\n",
       "              [ 1049,  5975,  ...,   284,   502],\n",
       "              [  284,  3285,  ...,   326,    11]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR),\n",
       " ttnn.Tensor([[  367,  2885,  ...,  1464,  1807],\n",
       "              [ 3619,   402,  ...,   271, 10899],\n",
       "              ...,\n",
       "              [ 5975,   284,  ...,   502,   284],\n",
       "              [ 3285,   326,  ...,    11,   287]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ttnn = ttnn.to_device(inputs_ttnn, device)\n",
    "targets_ttnn = ttnn.to_device(targets_ttnn, device)\n",
    "\n",
    "inputs_ttnn, targets_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8940f705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-0.53906, -0.62500,  ...,  0.75781, -0.21094],\n",
       "             [ 0.85547, -0.80859,  ..., -0.12158, -0.64062],\n",
       "             ...,\n",
       "             [ 0.49414,  1.69531,  ..., -1.25000,  0.45898],\n",
       "             [-0.90234, -0.91016,  ..., -0.05908, -0.94141]], shape=Shape([50257, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_weights_ttnn = ttnn.from_torch(\n",
    "    torch.randn(vocab_size, output_dim),\n",
    "    dtype=ttnn.bfloat16\n",
    ")\n",
    "token_embedding_weights_ttnn = ttnn.to_device(token_embedding_weights_ttnn, device)\n",
    "\n",
    "token_embedding_weights_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80b64ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[ 0.37500, -0.37305,  ..., -0.50391, -0.78516],\n",
       "              [ 1.14062, -0.59766,  ...,  0.87500, -0.83984],\n",
       "              ...,\n",
       "              [-0.67578,  0.89453,  ..., -0.59766,  2.20312],\n",
       "              [ 0.42969,  0.42578,  ...,  0.72266,  1.18750]],\n",
       "\n",
       "             [[-0.78906,  0.70312,  ..., -0.07568,  0.79688],\n",
       "              [ 0.36914, -1.42969,  ..., -2.81250,  0.01221],\n",
       "              ...,\n",
       "              [ 1.07031, -0.26562,  ...,  0.52734, -0.57422],\n",
       "              [-0.13281,  0.92188,  ..., -0.99219, -1.99219]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[ 0.45703, -1.40625,  ...,  0.71484, -2.64062],\n",
       "              [ 0.33594,  0.25391,  ..., -0.14551,  0.82422],\n",
       "              ...,\n",
       "              [ 0.71484, -0.55859,  ..., -0.55078, -0.31836],\n",
       "              [-0.82422, -0.77734,  ..., -0.17090, -0.05322]],\n",
       "\n",
       "             [[ 0.71484, -0.55859,  ..., -0.55078, -0.31836],\n",
       "              [ 0.29297, -0.41211,  ..., -0.04321,  0.75000],\n",
       "              ...,\n",
       "              [-0.03540, -0.50391,  ...,  0.15527, -0.14844],\n",
       "              [-0.92578, -0.19531,  ...,  0.73047, -0.34961]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings_ttnn = ttnn.embedding(inputs_ttnn, token_embedding_weights_ttnn)\n",
    "token_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1ab1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([    0,     1,  ...,     2,     3], shape=Shape([4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_inputs_ttnn = ttnn.arange(end=context_length, dtype=ttnn.uint32)\n",
    "positional_inputs_ttnn = ttnn.to_device(positional_inputs_ttnn, device)\n",
    "\n",
    "positional_inputs_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b80a344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "             [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "             ...,\n",
       "             [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "             [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]], shape=Shape([4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings_weights_ttnn = ttnn.from_torch(\n",
    "    torch.randn(context_length, output_dim),\n",
    "    dtype=ttnn.bfloat16\n",
    ")\n",
    "positional_embeddings_weights_ttnn = ttnn.to_device(positional_embeddings_weights_ttnn, device)\n",
    "\n",
    "positional_embeddings_weights_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a50e64a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "             [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "             ...,\n",
       "             [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "             [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]], shape=Shape([4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings_ttnn = ttnn.embedding(positional_inputs_ttnn, positional_embeddings_weights_ttnn)\n",
    "positional_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a638f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "              [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "              ...,\n",
       "              [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "              [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]],\n",
       "\n",
       "             [[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "              [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "              ...,\n",
       "              [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "              [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "              [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "              ...,\n",
       "              [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "              [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]],\n",
       "\n",
       "             [[ 0.50781,  0.34961,  ...,  1.02344, -0.26953],\n",
       "              [-0.48438, -0.66797,  ..., -1.00781, -0.40820],\n",
       "              ...,\n",
       "              [-0.49023, -0.19727,  ...,  0.14355, -1.26562],\n",
       "              [ 1.04688,  1.87500,  ..., -0.72656, -0.57422]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token embeddings -> [8, 4, 256]\n",
    "# position embeddings -> [4, 256]\n",
    "\n",
    "positional_embeddings_ttnn = ttnn.reshape(positional_embeddings_ttnn, (1, context_length, output_dim))\n",
    "positional_embeddings_ttnn = ttnn.repeat_interleave(positional_embeddings_ttnn, repeats=batch_size, dim=0)\n",
    "positional_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81da4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_pad_dims_split_rows_multicore\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_pad_dims_split_rows_multicore, tilize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[ 0.88281, -0.02344,  ...,  0.51953, -1.05469],\n",
       "              [ 0.65625, -1.26562,  ..., -0.13281, -1.25000],\n",
       "              ...,\n",
       "              [-1.16406,  0.69922,  ..., -0.45508,  0.93750],\n",
       "              [ 1.47656,  2.29688,  ..., -0.00391,  0.61328]],\n",
       "\n",
       "             [[-0.28125,  1.05469,  ...,  0.94922,  0.52734],\n",
       "              [-0.11523, -2.09375,  ..., -3.82812, -0.39648],\n",
       "              ...,\n",
       "              [ 0.58203, -0.46289,  ...,  0.67188, -1.84375],\n",
       "              [ 0.91406,  2.79688,  ..., -1.71875, -2.56250]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[ 0.96484, -1.05469,  ...,  1.74219, -2.90625],\n",
       "              [-0.14844, -0.41406,  ..., -1.15625,  0.41602],\n",
       "              ...,\n",
       "              [ 0.22461, -0.75781,  ..., -0.40820, -1.58594],\n",
       "              [ 0.22266,  1.10156,  ..., -0.89844, -0.62891]],\n",
       "\n",
       "             [[ 1.22656, -0.20898,  ...,  0.47266, -0.58984],\n",
       "              [-0.19141, -1.07812,  ..., -1.05469,  0.34180],\n",
       "              ...,\n",
       "              [-0.52734, -0.70312,  ...,  0.29883, -1.41406],\n",
       "              [ 0.12109,  1.67969,  ...,  0.00391, -0.92578]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings_ttnn = ttnn.to_layout(token_embeddings_ttnn, layout=ttnn.TILE_LAYOUT, device=device)\n",
    "positional_embeddings_ttnn = ttnn.to_layout(positional_embeddings_ttnn, layout=ttnn.TILE_LAYOUT, device=device)\n",
    "\n",
    "input_embeddings_ttnn = ttnn.add(\n",
    "    token_embeddings_ttnn,\n",
    "    positional_embeddings_ttnn    \n",
    ")\n",
    "\n",
    "input_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825f00e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb201d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4944bcb4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

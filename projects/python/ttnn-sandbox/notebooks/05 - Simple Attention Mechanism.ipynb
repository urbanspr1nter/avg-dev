{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46368c96",
   "metadata": {},
   "source": [
    "```\n",
    "B x C x D\n",
    "^   ^   ^\n",
    "|   |   |________ Embedding dimension\n",
    "|   |  \n",
    "|   |___ Context Dimension\n",
    "|    \n",
    "Batch dimension \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ac356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Your journey starts with one step\n",
    "context = torch.tensor(\n",
    "  [\n",
    "    [0.43, 0.15, 0.86], # Your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts \n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "521658ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.1500, 0.8600],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a15c8",
   "metadata": {},
   "source": [
    "## Selecting an Item for Query\n",
    "\n",
    "Given our `context`, we would like to compute for the second token, the context vector for the token corresponding to the word \"journey\".\n",
    "\n",
    "context vector is the \"attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e2106d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_2 = context[1]\n",
    "q_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef877e00",
   "metadata": {},
   "source": [
    "Compute the attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba288ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9346, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865]), torch.Size([6]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = torch.empty(len(context))\n",
    "for i, t_i in enumerate(context):\n",
    "  attention_scores[i] = torch.dot(q_2, t_i)\n",
    "\n",
    "attention_scores, attention_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588e363",
   "metadata": {},
   "source": [
    "Normalize the attention scores, and create the attention weights -- all elements in the attention weights vector should sum up to 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85da05f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1362, 0.2385, 0.2339, 0.1243, 0.1085, 0.1585])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc121e70",
   "metadata": {},
   "source": [
    "Sum the values inside the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "247e2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f056c40",
   "metadata": {},
   "source": [
    "Compute the context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "545fb4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6528, 0.5633])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = torch.zeros(len(q_2))\n",
    "for i, c_i in enumerate(context):\n",
    "  context_vector += attention_weights[i] * c_i\n",
    "\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd49c2",
   "metadata": {},
   "source": [
    "## Generalize Context Computation For All Tokens in Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9fcc66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9470, 0.9346, 0.9230, 0.4654, 0.4546, 0.6145],\n",
       "        [0.9346, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9230, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4654, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4546, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6145, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = context @ context.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27f3f3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2037, 0.2012, 0.1988, 0.1258, 0.1245, 0.1461],\n",
       "        [0.1362, 0.2385, 0.2339, 0.1243, 0.1085, 0.1585],\n",
       "        [0.1367, 0.2375, 0.2332, 0.1245, 0.1111, 0.1569],\n",
       "        [0.1423, 0.2077, 0.2048, 0.1464, 0.1265, 0.1723],\n",
       "        [0.1522, 0.1959, 0.1976, 0.1367, 0.1879, 0.1296],\n",
       "        [0.1365, 0.2189, 0.2132, 0.1424, 0.0990, 0.1900]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2661efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4424, 0.5955, 0.5695],\n",
       "        [0.4419, 0.6528, 0.5633],\n",
       "        [0.4432, 0.6509, 0.5621],\n",
       "        [0.4304, 0.6305, 0.5463],\n",
       "        [0.4671, 0.5912, 0.5219],\n",
       "        [0.4177, 0.6515, 0.5597]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ context\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4c554",
   "metadata": {},
   "source": [
    "## Simple Attention Mechanism in TTNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cbcc3",
   "metadata": {},
   "source": [
    "Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5551b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TTNN_CONFIG_OVERRIDES\"] = \"{\\\"enable_fast_runtime_mode\\\": false}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc58a67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"enable_fast_runtime_mode\": false}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"TTNN_CONFIG_OVERRIDES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57507726",
   "metadata": {},
   "source": [
    "Import everything needed and define the sample input context again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b449fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ttnn\n",
    "from ttnn.tracer import trace, visualize\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Your journey starts with one step\n",
    "context = torch.tensor(\n",
    "  [\n",
    "    [0.43, 0.15, 0.86], # Your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts \n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1afbdd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4300, 0.1500, 0.8600],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]]),\n",
       " torch.Size([6, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4b76cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 16:29:13.237 | DEBUG    | ttnn.tracer:visualize:443 - Dumping graph of the model to None\n",
      "2025-05-14 16:29:13.241 | DEBUG    | ttnn.tracer:visualize:443 - Dumping graph of the model to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Always | INFO     | Begin op: tt::tt_metal::detail::convert_python_tensor_to_tt_tensor\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::handle const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Layout>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Tile> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::detail::convert_python_tensor_to_tt_tensor\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | Begin op: ttnn::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::MemoryConfig> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | Begin op: Tensor::pad\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<float>\n",
      "                 Always | INFO     | End op: Tensor::pad\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | End op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: ttnn::experimental::view\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | Begin op: Tensor::reshape\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | End op: Tensor::reshape\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | End op: ttnn::experimental::view\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | End op: ttnn::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: tt::tt_metal::detail::convert_python_tensor_to_tt_tensor\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::handle const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Layout>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Tile> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::detail::convert_python_tensor_to_tt_tensor\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | Begin op: ttnn::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::MemoryConfig> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | Begin op: Tensor::pad\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::BorrowedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<float>\n",
      "                 Always | INFO     | End op: Tensor::pad\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | End op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: ttnn::experimental::view\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | Begin op: Tensor::reshape\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | End op: Tensor::reshape\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | End op: ttnn::experimental::view\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | End op: ttnn::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"410pt\" height=\"222pt\"\n",
       " viewBox=\"0.00 0.00 410.00 222.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 218)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-218 406,-218 406,4 -4,4\"/>\n",
       "<!-- torch_input_0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>torch_input_0</title>\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"173.5,-214 106.5,-214 106.5,-147 173.5,-147 173.5,-214\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108,-197.5 108,-212.5 173,-212.5 173,-197.5 108,-197.5\"/>\n",
       "<text text-anchor=\"start\" x=\"111.5\" y=\"-202.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.Tensor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108,-147.5 108,-196.5 173,-196.5 173,-147.5 108,-147.5\"/>\n",
       "<text text-anchor=\"start\" x=\"119.5\" y=\"-186.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-175.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(6, 3)</text>\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-164.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>ttnn.from_torch_5</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"/operation_buffer_report/1\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"192,-100 0,-100 0,0 192,0 192,-100\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1,-1 1,-99 90,-99 90,-1 1,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"3\" y=\"-47.5\" font-family=\"Linux libertine\" font-size=\"10.00\">1: ttnn.from_torch</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-50 91,-99 191,-99 191,-50 91,-50\"/>\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-89\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-78\" font-family=\"Linux libertine\" font-size=\"10.00\">(6, 3)</text>\n",
       "<text text-anchor=\"start\" x=\"110.5\" y=\"-67\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-1 91,-49 191,-49 191,-1 91,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"120\" y=\"-39\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"112\" y=\"-28\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"93\" y=\"-17\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"112.5\" y=\"-6\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- torch_input_0&#45;&gt;ttnn.from_torch_5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>torch_input_0:#0&#45;&gt;ttnn.from_torch_5:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141,-147C141,-130.03 141,-123.4 141,-110.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.5,-110 141,-100 137.5,-110 144.5,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"156.5\" y=\"-121\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- torch_input_6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>torch_input_6</title>\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"383.5,-214 316.5,-214 316.5,-147 383.5,-147 383.5,-214\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"318,-197.5 318,-212.5 383,-212.5 383,-197.5 318,-197.5\"/>\n",
       "<text text-anchor=\"start\" x=\"321.5\" y=\"-202.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.Tensor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"318,-147.5 318,-196.5 383,-196.5 383,-147.5 318,-147.5\"/>\n",
       "<text text-anchor=\"start\" x=\"329.5\" y=\"-186.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"338.5\" y=\"-175.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(3, 6)</text>\n",
       "<text text-anchor=\"start\" x=\"320\" y=\"-164.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_11 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ttnn.from_torch_11</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"/operation_buffer_report/2\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"402,-100 210,-100 210,0 402,0 402,-100\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"211,-1 211,-99 300,-99 300,-1 211,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"213\" y=\"-47.5\" font-family=\"Linux libertine\" font-size=\"10.00\">2: ttnn.from_torch</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"301,-50 301,-99 401,-99 401,-50 301,-50\"/>\n",
       "<text text-anchor=\"start\" x=\"334\" y=\"-89\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"339\" y=\"-78\" font-family=\"Linux libertine\" font-size=\"10.00\">(3, 6)</text>\n",
       "<text text-anchor=\"start\" x=\"320.5\" y=\"-67\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"301,-1 301,-49 401,-49 401,-1 301,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"330\" y=\"-39\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"322\" y=\"-28\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([3, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"303\" y=\"-17\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"322.5\" y=\"-6\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- torch_input_6&#45;&gt;ttnn.from_torch_11 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>torch_input_6:#0&#45;&gt;ttnn.from_torch_11:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351,-147C351,-130.03 351,-123.4 351,-110.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.5,-110 351,-100 347.5,-110 354.5,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"366.5\" y=\"-121\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7778fa7ffac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with trace():\n",
    "  context_ttnn = ttnn.from_torch(context, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT)\n",
    "  context_transposed_ttnn = ttnn.from_torch(context.T, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT)\n",
    "\n",
    "visualize(context_ttnn)\n",
    "visualize(context_transposed_ttnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971fd3d",
   "metadata": {},
   "source": [
    "1. Transfer the context and transposed version of the context ttnn tensors to the device\n",
    "2. Compute the attention scores using `ttnn.matmul`. Assume both the context and context transposed ttnn tensors are already in the device and in `TILE_LAYOUT`.\n",
    "3. Perform softmax on the resulting attention scores tensor (was result in step 2)\n",
    "4. Compute the context vectors using `ttnn.matmul` against attention weights and context. Attention weights are normalized attention scores. (this is result from step 3)\n",
    "5. Transfer the results of step 4, the context vectors back to CPU as torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9129d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-05-14 16:38:21.319\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-05-14 16:38:21.333\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-14 16:38:21.336\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-05-14 16:38:21.337\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-14 16:38:21.337\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-05-14 16:38:21.337\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-05-14 16:38:21.347\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n",
      "                 Always | INFO     | Begin op: Tensor::to_device\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | End op: Tensor::to_device\n",
      "                 Always | INFO     | Begin op: Tensor::to_device\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | End op: Tensor::to_device\n",
      "                 Always | INFO     | Begin op: ttnn::matmul\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::MemoryConfig const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<ttnn::operations::matmul::MatmulMultiCoreProgramConfig, ttnn::operations::matmul::MatmulMultiCoreNonOptimizedReuseProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCastProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCast1DProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCastDRAMShardedProgramConfig> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<ttnn::GrayskullComputeKernelConfig, ttnn::WormholeComputeKernelConfig> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<ttnn::types::CoreGrid const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Tile const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<std::__1::monostate, tt::tt_metal::experimental::GlobalCircularBuffer, ttnn::global_circular_buffer::MultiDeviceGlobalCircularBuffer> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::stl::StrongType<unsigned char, tt::tt_metal::SubDeviceIdTag>> const>\n",
      "                 Always | INFO     | Begin op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | Begin op: Matmul\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::OldInfraDeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>::tensor_args_t const>\n",
      "                 Always | INFO     | Begin op: tt::tt_metal::create_device_tensor\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::DataType>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::create_device_tensor\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 4,5. First unused index: 2. Kernels: reader_bmm_tile_layout_in1_sender_writer_padding, reader_bmm_tile_layout_in0_sender_padding, bmm_large_block_zm_fused_bias_activation\n",
      "                 Always | INFO     | End op: Matmul\n",
      "                 Always | INFO     | End op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | End op: ttnn::matmul\n",
      "                 Always | INFO     | Begin op: ttnn::softmax\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<signed char const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::MemoryConfig> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<ttnn::GrayskullComputeKernelConfig, ttnn::WormholeComputeKernelConfig> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | Begin op: ttnn::reshape\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::stl::StrongType<unsigned char, ttnn::QueueIdTag> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | Begin op: ttnn::experimental::view\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | Begin op: Tensor::reshape\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | End op: Tensor::reshape\n",
      "                 Always | INFO     | End op: ttnn::experimental::view\n",
      "                 Always | INFO     | End op: ttnn::reshape\n",
      "                 Always | INFO     | Begin op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | Begin op: Softmax\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::OldInfraDeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>::tensor_args_t const>\n",
      "                 Always | INFO     | Begin op: tt::tt_metal::create_device_tensor\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::DataType>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::create_device_tensor\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2,5,6,7,11. First unused index: 1. Kernels: writer_unary_interleaved_start_id_blocked_sm, reader_unary_interleaved_sm, softmax\n",
      "                 Always | INFO     | End op: Softmax\n",
      "                 Always | INFO     | End op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | Begin op: ttnn::reshape\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::stl::StrongType<unsigned char, ttnn::QueueIdTag> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | Begin op: ttnn::experimental::view\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape>\n",
      "                 Always | INFO     | Begin op: Tensor::reshape\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | End op: Tensor::reshape\n",
      "                 Always | INFO     | End op: ttnn::experimental::view\n",
      "                 Always | INFO     | End op: ttnn::reshape\n",
      "                 Always | INFO     | End op: ttnn::softmax\n",
      "                 Always | INFO     | Begin op: ttnn::matmul\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::MemoryConfig const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::DataType const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<ttnn::operations::matmul::MatmulMultiCoreProgramConfig, ttnn::operations::matmul::MatmulMultiCoreNonOptimizedReuseProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCastProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCast1DProgramConfig, ttnn::operations::matmul::MatmulMultiCoreReuseMultiCastDRAMShardedProgramConfig> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<ttnn::GrayskullComputeKernelConfig, ttnn::WormholeComputeKernelConfig> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<ttnn::types::CoreGrid const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::tt_metal::Tile const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<std::__1::variant<std::__1::monostate, tt::tt_metal::experimental::GlobalCircularBuffer, ttnn::global_circular_buffer::MultiDeviceGlobalCircularBuffer> const> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::optional<tt::stl::StrongType<unsigned char, tt::tt_metal::SubDeviceIdTag>> const>\n",
      "                 Always | INFO     | Begin op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | Begin op: Matmul\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>> const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::operation::OldInfraDeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>::tensor_args_t const>\n",
      "                 Always | INFO     | Begin op: tt::tt_metal::create_device_tensor\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Shape const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::DataType>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::MemoryConfig const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::create_device_tensor\n",
      "                 Always | INFO     | End op: Matmul\n",
      "                 Always | INFO     | End op: ttnn::prim::old_infra_device_operation\n",
      "                 Always | INFO     | End op: ttnn::matmul\n",
      "                 Always | INFO     | Begin op: Tensor::cpu\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool>\n",
      "                 Always | INFO     | End op: Tensor::cpu\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::Layout>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<tt::tt_metal::IDevice*>\n",
      "                 Always | INFO     | End op: Tensor::to_layout\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | Begin op: tt::tt_metal::detail::convert_tt_tensor_to_torch_tensor\n",
      "                 Always | INFO     | Tensor doesn't have buffer, but storage is tt::tt_metal::OwnedStorage\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<bool const>\n",
      "                 Always | INFO     | End op: tt::tt_metal::detail::convert_tt_tensor_to_torch_tensor\n",
      "                 Always | INFO     | output any type name ignored: std::__1::reference_wrapper<pybind11::object>\n",
      "                 Always | INFO     | Begin op: (torch) __get__\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::args const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::kwargs const>\n",
      "                 Always | INFO     | End op: (torch) __get__\n",
      "                 Always | INFO     | output any type name ignored: std::__1::reference_wrapper<pybind11::object>\n",
      "                 Always | INFO     | Begin op: (torch) __get__\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::args const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::kwargs const>\n",
      "                 Always | INFO     | End op: (torch) __get__\n",
      "                 Always | INFO     | output any type name ignored: std::__1::reference_wrapper<pybind11::object>\n",
      "                 Always | INFO     | Begin op: (torch) __get__\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::args const>\n",
      "                 Always | INFO     | input any type name ignored: std::__1::reference_wrapper<pybind11::kwargs const>\n",
      "                 Always | INFO     | End op: (torch) __get__\n",
      "                 Always | INFO     | output any type name ignored: std::__1::reference_wrapper<pybind11::object>\n",
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TracedTorchTensor([[0.4414, 0.5898, 0.5664],\n",
       "                   [0.4355, 0.6523, 0.5625],\n",
       "                   [0.4375, 0.6484, 0.5625],\n",
       "                   [0.4297, 0.6250, 0.5430],\n",
       "                   [0.4609, 0.5859, 0.5195],\n",
       "                   [0.4180, 0.6523, 0.5586]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n",
    "\n",
    "with trace():\n",
    "  context_ttnn = ttnn.to_device(context_ttnn, device)\n",
    "  context_transposed_ttnn = ttnn.to_device(context_transposed_ttnn, device)\n",
    "\n",
    "  attention_scores_ttnn = ttnn.matmul(context_ttnn, context_transposed_ttnn)\n",
    "  attention_weights_ttnn = ttnn.softmax(attention_scores_ttnn, dim=-1)\n",
    "\n",
    "  context_vectors_ttnn = ttnn.matmul(attention_weights_ttnn, context_ttnn)\n",
    "\n",
    "  context_vectors_torch = ttnn.to_torch(context_vectors_ttnn, device=device)\n",
    "\n",
    "ttnn.close_device(device)\n",
    "\n",
    "context_vectors_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eeb2e3",
   "metadata": {},
   "source": [
    "Torch version:\n",
    "\n",
    "```\n",
    "tensor([[0.4424, 0.5955, 0.5695],\n",
    "        [0.4419, 0.6528, 0.5633],\n",
    "        [0.4432, 0.6509, 0.5621],\n",
    "        [0.4304, 0.6305, 0.5463],\n",
    "        [0.4671, 0.5912, 0.5219],\n",
    "        [0.4177, 0.6515, 0.5597]])\n",
    "```\n",
    "\n",
    "ttnn version:\n",
    "```\n",
    "TracedTorchTensor([[0.4414, 0.5898, 0.5664],\n",
    "                   [0.4355, 0.6523, 0.5625],\n",
    "                   [0.4375, 0.6484, 0.5625],\n",
    "                   [0.4297, 0.6250, 0.5430],\n",
    "                   [0.4609, 0.5859, 0.5195],\n",
    "                   [0.4180, 0.6523, 0.5586]], dtype=torch.bfloat16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9abeda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 16:40:07.309 | DEBUG    | ttnn.tracer:visualize:443 - Dumping graph of the model to None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"528pt\" height=\"1040pt\"\n",
       " viewBox=\"0.00 0.00 528.00 1040.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1036)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1036 524,-1036 524,4 -4,4\"/>\n",
       "<!-- torch_input_0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>torch_input_0</title>\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"190.5,-1032 123.5,-1032 123.5,-965 190.5,-965 190.5,-1032\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-1015.5 125,-1030.5 190,-1030.5 190,-1015.5 125,-1015.5\"/>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-1020.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.Tensor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-965.5 125,-1014.5 190,-1014.5 190,-965.5 125,-965.5\"/>\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-1004.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"145.5\" y=\"-993.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(6, 3)</text>\n",
       "<text text-anchor=\"start\" x=\"127\" y=\"-982.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>ttnn.from_torch_5</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"/operation_buffer_report/1\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"209,-918 17,-918 17,-818 209,-818 209,-918\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"18,-819 18,-917 107,-917 107,-819 18,-819\"/>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-865.5\" font-family=\"Linux libertine\" font-size=\"10.00\">1: ttnn.from_torch</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108,-868 108,-917 208,-917 208,-868 108,-868\"/>\n",
       "<text text-anchor=\"start\" x=\"141\" y=\"-907\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"146\" y=\"-896\" font-family=\"Linux libertine\" font-size=\"10.00\">(6, 3)</text>\n",
       "<text text-anchor=\"start\" x=\"127.5\" y=\"-885\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108,-819 108,-867 208,-867 208,-819 108,-819\"/>\n",
       "<text text-anchor=\"start\" x=\"137\" y=\"-857\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-846\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-835\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"129.5\" y=\"-824\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- torch_input_0&#45;&gt;ttnn.from_torch_5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>torch_input_0:#0&#45;&gt;ttnn.from_torch_5:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158,-965C158,-948.03 158,-941.4 158,-928.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-928 158,-918 154.5,-928 161.5,-928\"/>\n",
       "<text text-anchor=\"middle\" x=\"173.5\" y=\"-939\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.to_device_14 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>ttnn.to_device_14</title>\n",
       "<g id=\"a_node5\"><a xlink:href=\"/operation_buffer_report/3\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"232,-771 0,-771 0,-661 232,-661 232,-771\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1,-662 1,-770 83,-770 83,-662 1,-662\"/>\n",
       "<text text-anchor=\"start\" x=\"3\" y=\"-713.5\" font-family=\"Linux libertine\" font-size=\"10.00\">3: ttnn.to_device</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84,-722 84,-770 231,-770 231,-722 84,-722\"/>\n",
       "<text text-anchor=\"start\" x=\"140.5\" y=\"-760\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-749\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"109.5\" y=\"-738\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-727\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84,-662 84,-721 231,-721 231,-662 84,-662\"/>\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-711\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"109.5\" y=\"-689\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-678\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-667\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_5&#45;&gt;ttnn.to_device_14 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>ttnn.from_torch_5:#0&#45;&gt;ttnn.to_device_14:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158,-818C158,-801.03 158,-794.4 158,-781.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-781 158,-771 154.5,-781 161.5,-781\"/>\n",
       "<text text-anchor=\"middle\" x=\"173.5\" y=\"-792\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- torch_input_6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>torch_input_6</title>\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"478.5,-1032 411.5,-1032 411.5,-965 478.5,-965 478.5,-1032\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"413,-1015.5 413,-1030.5 478,-1030.5 478,-1015.5 413,-1015.5\"/>\n",
       "<text text-anchor=\"start\" x=\"416.5\" y=\"-1020.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.Tensor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"413,-965.5 413,-1014.5 478,-1014.5 478,-965.5 413,-965.5\"/>\n",
       "<text text-anchor=\"start\" x=\"424.5\" y=\"-1004.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"433.5\" y=\"-993.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(3, 6)</text>\n",
       "<text text-anchor=\"start\" x=\"415\" y=\"-982.5\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_11 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ttnn.from_torch_11</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"/operation_buffer_report/2\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"497,-918 305,-918 305,-818 497,-818 497,-918\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"306,-819 306,-917 395,-917 395,-819 306,-819\"/>\n",
       "<text text-anchor=\"start\" x=\"308\" y=\"-865.5\" font-family=\"Linux libertine\" font-size=\"10.00\">2: ttnn.from_torch</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"396,-868 396,-917 496,-917 496,-868 396,-868\"/>\n",
       "<text text-anchor=\"start\" x=\"429\" y=\"-907\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"434\" y=\"-896\" font-family=\"Linux libertine\" font-size=\"10.00\">(3, 6)</text>\n",
       "<text text-anchor=\"start\" x=\"415.5\" y=\"-885\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.float32</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"396,-819 396,-867 496,-867 496,-819 396,-819\"/>\n",
       "<text text-anchor=\"start\" x=\"425\" y=\"-857\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"417\" y=\"-846\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([3, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"398\" y=\"-835\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"417.5\" y=\"-824\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- torch_input_6&#45;&gt;ttnn.from_torch_11 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>torch_input_6:#0&#45;&gt;ttnn.from_torch_11:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446,-965C446,-948.03 446,-941.4 446,-928.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.5,-928 446,-918 442.5,-928 449.5,-928\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-939\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.to_device_17 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>ttnn.to_device_17</title>\n",
       "<g id=\"a_node6\"><a xlink:href=\"/operation_buffer_report/4\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"520,-771 288,-771 288,-661 520,-661 520,-771\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"289,-662 289,-770 371,-770 371,-662 289,-662\"/>\n",
       "<text text-anchor=\"start\" x=\"291\" y=\"-713.5\" font-family=\"Linux libertine\" font-size=\"10.00\">4: ttnn.to_device</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"372,-722 372,-770 519,-770 519,-722 372,-722\"/>\n",
       "<text text-anchor=\"start\" x=\"428.5\" y=\"-760\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"416.5\" y=\"-749\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([3, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"397.5\" y=\"-738\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"417\" y=\"-727\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"372,-662 372,-721 519,-721 519,-662 372,-662\"/>\n",
       "<text text-anchor=\"start\" x=\"424.5\" y=\"-711\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"416.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([3, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"397.5\" y=\"-689\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"417\" y=\"-678\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"374\" y=\"-667\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.from_torch_11&#45;&gt;ttnn.to_device_17 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ttnn.from_torch_11:#0&#45;&gt;ttnn.to_device_17:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446,-818C446,-801.03 446,-794.4 446,-781.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.5,-781 446,-771 442.5,-781 449.5,-781\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-792\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.matmul_20 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>ttnn.matmul_20</title>\n",
       "<g id=\"a_node7\"><a xlink:href=\"/operation_buffer_report/5\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"520,-614 148,-614 148,-493 520,-493 520,-614\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"149,-493.5 149,-612.5 223,-612.5 223,-493.5 149,-493.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-550.5\" font-family=\"Linux libertine\" font-size=\"10.00\">5: ttnn.matmul</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"224,-553.5 224,-612.5 371,-612.5 371,-553.5 224,-553.5\"/>\n",
       "<text text-anchor=\"start\" x=\"280.5\" y=\"-602.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"268.5\" y=\"-591.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"249.5\" y=\"-580.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"269\" y=\"-569.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"226\" y=\"-558.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"372,-553.5 372,-612.5 519,-612.5 519,-553.5 372,-553.5\"/>\n",
       "<text text-anchor=\"start\" x=\"428.5\" y=\"-602.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 1</text>\n",
       "<text text-anchor=\"start\" x=\"416.5\" y=\"-591.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([3, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"397.5\" y=\"-580.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"417\" y=\"-569.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"374\" y=\"-558.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"224,-493.5 224,-552.5 519,-552.5 519,-493.5 224,-493.5\"/>\n",
       "<text text-anchor=\"start\" x=\"350.5\" y=\"-542.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"342.5\" y=\"-531.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"323.5\" y=\"-520.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"343\" y=\"-509.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"300\" y=\"-498.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.to_device_14&#45;&gt;ttnn.matmul_20 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>ttnn.to_device_14:#0&#45;&gt;ttnn.matmul_20:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232,-691C251.58,-691 286.37,-649.25 295.01,-623.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.51,-623.99 297,-613.5 291.64,-622.64 298.51,-623.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"307.5\" y=\"-635\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.matmul_26 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>ttnn.matmul_26</title>\n",
       "<g id=\"a_node9\"><a xlink:href=\"/operation_buffer_report/7\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"376,-278 4,-278 4,-157 376,-157 376,-278\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5,-157.5 5,-276.5 79,-276.5 79,-157.5 5,-157.5\"/>\n",
       "<text text-anchor=\"start\" x=\"7\" y=\"-214.5\" font-family=\"Linux libertine\" font-size=\"10.00\">7: ttnn.matmul</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80,-217.5 80,-276.5 227,-276.5 227,-217.5 80,-217.5\"/>\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-266.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"124.5\" y=\"-255.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"105.5\" y=\"-244.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"125\" y=\"-233.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-222.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"228,-217.5 228,-276.5 375,-276.5 375,-217.5 228,-217.5\"/>\n",
       "<text text-anchor=\"start\" x=\"284.5\" y=\"-266.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 1</text>\n",
       "<text text-anchor=\"start\" x=\"272.5\" y=\"-255.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"253.5\" y=\"-244.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"273\" y=\"-233.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"230\" y=\"-222.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80,-157.5 80,-216.5 375,-216.5 375,-157.5 80,-157.5\"/>\n",
       "<text text-anchor=\"start\" x=\"206.5\" y=\"-206.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"198.5\" y=\"-195.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"179.5\" y=\"-184.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"156\" y=\"-162.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.to_device_14&#45;&gt;ttnn.matmul_26 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>ttnn.to_device_14:#0&#45;&gt;ttnn.matmul_26:$1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158,-661C158,-638.47 143.3,-636.12 139,-614 111.98,-475.09 57.17,-398.25 155,-296 175.09,-275 274.28,-302.32 297.24,-286.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.35,-287.97 302,-277.5 294.19,-284.66 300.35,-287.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-467\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 1</text>\n",
       "</g>\n",
       "<!-- ttnn.to_device_17&#45;&gt;ttnn.matmul_20 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>ttnn.to_device_17:#0&#45;&gt;ttnn.matmul_20:$1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446,-661C446,-643.68 446,-637.02 446,-623.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.5,-623.5 446,-613.5 442.5,-623.5 449.5,-623.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-635\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 1</text>\n",
       "</g>\n",
       "<!-- ttnn.softmax_23 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>ttnn.softmax_23</title>\n",
       "<g id=\"a_node8\"><a xlink:href=\"/operation_buffer_report/6\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"410,-446 184,-446 184,-325 410,-325 410,-446\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"185,-325.5 185,-444.5 261,-444.5 261,-325.5 185,-325.5\"/>\n",
       "<text text-anchor=\"start\" x=\"187\" y=\"-382.5\" font-family=\"Linux libertine\" font-size=\"10.00\">6: ttnn.softmax</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"262,-385.5 262,-444.5 409,-444.5 409,-385.5 262,-385.5\"/>\n",
       "<text text-anchor=\"start\" x=\"318.5\" y=\"-434.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"306.5\" y=\"-423.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"287.5\" y=\"-412.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"307\" y=\"-401.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"264\" y=\"-390.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"262,-325.5 262,-384.5 409,-384.5 409,-325.5 262,-325.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-374.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"306.5\" y=\"-363.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 6])</text>\n",
       "<text text-anchor=\"start\" x=\"287.5\" y=\"-352.5\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"307\" y=\"-341.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"264\" y=\"-330.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.matmul_20&#45;&gt;ttnn.softmax_23 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>ttnn.matmul_20:#0&#45;&gt;ttnn.softmax_23:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372,-493C372,-470.44 345.89,-471.07 338.14,-455.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"341.54,-454.53 336,-445.5 334.7,-456.01 341.54,-454.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-467\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.softmax_23&#45;&gt;ttnn.matmul_26 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>ttnn.softmax_23:#0&#45;&gt;ttnn.matmul_26:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M336,-325C336,-244.75 169.07,-351.11 154.07,-287.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"157.54,-287.07 153,-277.5 150.58,-287.81 157.54,-287.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"346.5\" y=\"-299\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "<!-- ttnn.to_torch_28 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>ttnn.to_torch_28</title>\n",
       "<g id=\"a_node10\"><a xlink:href=\"/operation_buffer_report/8\" xlink:title=\"&lt;TABLE&gt;\">\n",
       "<polygon fill=\"#dcdcdc\" stroke=\"black\" points=\"301.5,-110 74.5,-110 74.5,0 301.5,0 301.5,-110\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"76,-1 76,-109 153,-109 153,-1 76,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"78\" y=\"-52.5\" font-family=\"Linux libertine\" font-size=\"10.00\">8: ttnn.to_torch</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154,-50 154,-109 301,-109 301,-50 154,-50\"/>\n",
       "<text text-anchor=\"start\" x=\"210.5\" y=\"-99\" font-family=\"Linux libertine\" font-size=\"10.00\">Input 0</text>\n",
       "<text text-anchor=\"start\" x=\"198.5\" y=\"-88\" font-family=\"Linux libertine\" font-size=\"10.00\">Shape([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"179.5\" y=\"-77\" font-family=\"Linux libertine\" font-size=\"10.00\">DataType.BFLOAT16</text>\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-66\" font-family=\"Linux libertine\" font-size=\"10.00\">Layout: TILE</text>\n",
       "<text text-anchor=\"start\" x=\"156\" y=\"-55\" font-family=\"Linux libertine\" font-size=\"10.00\">Memory: DRAM, INTERLEAVED</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154,-1 154,-49 301,-49 301,-1 154,-1\"/>\n",
       "<text text-anchor=\"start\" x=\"206.5\" y=\"-39\" font-family=\"Linux libertine\" font-size=\"10.00\">Output 0</text>\n",
       "<text text-anchor=\"start\" x=\"190\" y=\"-28\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.Size([6, 3])</text>\n",
       "<text text-anchor=\"start\" x=\"194\" y=\"-17\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.bfloat16</text>\n",
       "<text text-anchor=\"start\" x=\"197\" y=\"-6\" font-family=\"Linux libertine\" font-size=\"10.00\">torch.strided</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- ttnn.matmul_26&#45;&gt;ttnn.to_torch_28 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>ttnn.matmul_26:#0&#45;&gt;ttnn.to_torch_28:$0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M228,-157C228,-140.03 228,-133.4 228,-120.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.5,-120 228,-110 224.5,-120 231.5,-120\"/>\n",
       "<text text-anchor=\"middle\" x=\"243.5\" y=\"-131\" font-family=\"Times,serif\" font-size=\"10.00\">0 &#45;&gt; 0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7778fa7b9660>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(context_vectors_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963632f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
